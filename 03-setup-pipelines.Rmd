# Setup Pipelines and Images

## Get CellProfiler Pipelines

Cell Painting pipelines are stored in a GitHub repo.
If you are using a new pipeline, be sure to add it to the repo first.
Follow instructions on https://github.com/broadinstitute/imaging-platform-pipelines for adding new pipelines.

```sh
cd ~/efs/${PROJECT_NAME}/workspace/
mkdir github
cd github/
git clone https://github.com/broadinstitute/imaging-platform-pipelines.git
cd ..
ln -s github/imaging-platform-pipelines pipelines
```

This is the resulting structure of `github` and `pipelines` on EFS (one level below `workspace`):

```
├── github
│    └── imaging-platform-pipelines
└── pipelines -> github/imaging-platform-pipelines
```

## Specify Pipeline Set

```
PIPELINE_SET=cellpainting_a549_20x_with_bf_phenix_bin1
```

Ensure that, both, `analysis.cppipe` as well as `illum.cppipe` are present for this set.
As well, each pipeline should have a `_without_batchfile` version of it in the same directory.
It's easy to create such a version of the pipeline - simply copy it and set `enabled=False` for the `CreateBatchFiles` module (like [here](https://github.com/broadinstitute/imaging-platform-pipelines/blob/master/cellpainting_u2os_20x_imagexpress/illum_without_batchfile.cppipe#L384)).

## Upload Images

Your image files should be uploaded to AWS from your local compute environment via a tool like Cyberduck or the AWS CLI (`aws s3 sync /local/path s3://BUCKET/PROJECT_NAME/BATCH_ID/images`) (see also Appendix A.2 for more information on folder structures).
Some important tips BEFORE uploading (these are much more difficult to fix once uploaded):

* Ensure your image sets are complete i.e. all image sets should have the same number of channels and z-planes, and that this is true across the entire batch of plates you are processing.
* Avoid folder names with spaces
* Plate names should not have leading 0's (ie `123` not `000123`)
* VERY  IMPORTANT- If using `pe2loaddata` (described later) to generate your image CSVs, please ensure the folder name contains the plate name given when imaging on the Phenix microscope (can be checked in the `Index.idx.xml`)

## Prepare Images

(if using `pe2loaddata` to create image sets)

Create soft link to the image folder.
Note that the relevant S3 bucket has been mounted at `/home/ubuntu/bucket/`.

```{block2, type='rmdnote'}
The folder structure for `images` differs between `S3` and `EFS`.
This can be potentially confusing.
However note that the step below simply creates a soft link to the images in S3; no files are copied.
Further, when `pe2loaddata` is run (later in the process, via `create_csv_from_xml.sh`) it resolves the soft link, so the the resulting LoadData CSV files end up having the paths to the images as they exist on S3.
Thus the step below (of creating a softlink) only serves the purpose of making the `images` folder have a similar structure as the others (e.g. `load_data_csv`, `metadata`, `analysis`).
```

```sh
cd ~/efs/${PROJECT_NAME}/workspace/
mkdir images
cd images
ln -s ~/bucket/projects/${PROJECT_NAME}/${BATCH_ID}/images/ ${BATCH_ID}
cd ..
```

This is the resulting structure of the image folder on EFS (one level below `workspace`):

```
└── images
    └── 2016_04_01_a549_48hr_batch1 -> /home/ubuntu/bucket/projects/2015_10_05_DrugRepurposing_AravindSubramanian_GolubLab_Broad/2016_04_01_a549_48hr_batch1/images/
```

This is the structure of the image folder on S3 (one level above `workspace`, under the folder `2016_04_01_a549_48hr_batch1`.)
Here, only one plate (`SQ00015167__2016-04-21T03_34_00-Measurement1`) is show but there are often many more.

```
└── images
    └── 2016_04_01_a549_48hr_batch1
        └── SQ00015167__2016-04-21T03_34_00-Measurement1
            ├── Assaylayout
            ├── FFC_Profile
            └── Images
                ├── r01c01f01p01-ch1sk1fk1fl1.tiff
                ├── r01c01f01p01-ch2sk1fk1fl1.tiff
                ├── r01c01f01p01-ch3sk1fk1fl1.tiff
                ├── r01c01f01p01-ch4sk1fk1fl1.tiff
                └── r01c01f01p01-ch5sk1fk1fl1.tiff
```

`SQ00015167__2016-04-21T03_34_00-Measurement1` is the typical nomenclature followed by Broad Chemical Biology Platform for plate names.
`Measurement1` indicates the first attempt to image the plate.
`Measurement2` indicates second attempt and so on.
Ensure that there's only one folder corresponding to a plate before running `create_csv_from_xml.sh` below (it gracefully exits if not).

## Create List of Plates

Create a text file with one plate id per line.
The plate IDs, if using `pe2loaddata`, must match the plate IDs given when operating the Phenix.
Otherwise, they should match CellProfiler's understanding of the `Plate` grouping variable, whether that is explicitly stated in a loaddata CSV OR produced from the Metadata module if the CSVs and/or batch files are created using CellProfiler's input modules.
For downstream purposes, i.e. `cytominer`, you may choose to use only so much of the plate name as you need to keep the plates unique (e.g. `SQ00015167` instead of `SQ00015167__2016-04-21T03_34_00-Measurement1` to keep the names compact.

```sh
mkdir -p scratch/${BATCH_ID}/

PLATES=$(readlink -f ~/efs/${PROJECT_NAME}/workspace/scratch/${BATCH_ID}/plates_to_process.txt)

echo "SQ00015130 SQ00015168 SQ00015167 SQ00015166 SQ00015165"|tr " " "\n" > ${PLATES}
```

## Create LoadData CSVs

The script below works only for Phenix microscopes – it reads a standard XML file (`Index.idx.xml`) and writes a LoadData csv file.
For other microscopes, you will have to roll your own (see Appendix B).
The script below requires `config.yml`, which specifies (1) the mapping between channel names in `Index.idx.xml` and the channel names in the CellProfiler pipelines and (2) metadata to extract from `Index.idx.xml`.

Here's a truncated sample `config.yml` (see the repository for the full file)

```
channels:
    HOECHST 33342: OrigDNA
    Alexa 568: OrigAGP
    Alexa 647: OrigMito
    Alexa 488: OrigER
    488 long: OrigRNA
    Brightfieldlow: OrigBrightfield
metadata:
    Row: Row
    Col: Col
    FieldID: FieldID
    PlaneID: PlaneID
    ChannelID: ChannelID
    ChannelName: ChannelName
    ImageResolutionX: ImageResolutionX
    [...]
```

Often, the values of the keys for channels are different in `Index.idx.xml`, so for example, above, we have `Brightfieldlow: OrigBrightfield` but the keys for channels could be different in `Index.idx.xml`:

```
$ tail -n 500 Index.idx.xml|grep ChannelName|sort -u

      <ChannelName>488 long</ChannelName>
      <ChannelName>Alexa 488</ChannelName>
      <ChannelName>Alexa 568</ChannelName>
      <ChannelName>Alexa 647</ChannelName>
      <ChannelName>Brightfield CP</ChannelName>
      <ChannelName>HOECHST 33342</ChannelName>
```

The brightfield channel is tagged `Brightfield CP` in `Index.idx.xml`.
Fix this discrepancy by editing `config.yml`:

```
    HOECHST 33342: OrigDNA
    Alexa 568: OrigAGP
    Alexa 647: OrigMito
    Alexa 488: OrigER
    488 long: OrigRNA
    Brightfield CP: OrigBrightfield
```

```{block2, type='rmdnote'}
- Ensure that all the metadata fields defined in `config.yml` are present in the `Index.idx.xml`.
- Ensure that the channel names are the same in `config.yml` and `Index.idx.xml`
- Ensure that the LoadData csv files don't already exist; if they do, delete them.
- The `max-procs` option is set as 1 because pe2loaddata accesses the image files on `s3fs`, which doesn't handle multiple requests well.
```

```sh
cd ~/efs/${PROJECT_NAME}/workspace/software/cellpainting_scripts/
pyenv shell 2.7.12
parallel \
  --max-procs 1 \
  --eta \
  --joblog ../../log/${BATCH_ID}/create_csv_from_xml.log \
  --results ../../log/${BATCH_ID}/create_csv_from_xml \
  --files \
  --keep-order \
  ./create_csv_from_xml.sh \
  -b ${BATCH_ID} \
  --plate {1} :::: ${PLATES}
cd ../../
```

This is the resulting structure of `load_data_csv` on EFS (one level below `workspace`).
Files for only `SQ00015167` are shown.

```
└── load_data_csv
    └── 2016_04_01_a549_48hr_batch1
        └── SQ00015167
            ├── load_data.csv
            └── load_data_with_illum.csv
```

`load_data.csv` will be used by `illum.cppipe` and, optionally, `qc.cppipe`.
`load_data_with_illum.csv` will be used by `analysis.cppipe`.
When creating `load_data_with_illum.csv`, the script assumes a specific location for the folder containing the illumination correction files.

Copy the load data files to S3:

```sh
aws s3 sync \
  ../../load_data_csv/${BATCH_ID}/ \
  s3://${BUCKET}/projects/${PROJECT_NAME}/workspace/load_data_csv/${BATCH_ID}/
```
