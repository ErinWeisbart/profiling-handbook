<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 5 Create Profiles | Image-based Profiling Handbook</title>
  <meta name="description" content="This is a handbook for processing image-based profiling datasets using CellProfiler and pycytominer" />
  <meta name="generator" content="bookdown 0.22.5 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 5 Create Profiles | Image-based Profiling Handbook" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="This is a handbook for processing image-based profiling datasets using CellProfiler and pycytominer" />
  <meta name="github-repo" content="rstudio/bookdown-demo" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 5 Create Profiles | Image-based Profiling Handbook" />
  
  <meta name="twitter:description" content="This is a handbook for processing image-based profiling datasets using CellProfiler and pycytominer" />
  

<meta name="author" content="Beth Cimini, Tim Becker, Shantanu Singh, Gregory Way, Hamdah Abbasi" />


<meta name="date" content="2021-06-25" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="run-each-cellprofiler-step.html"/>
<link rel="next" href="appendix-a.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<link href="libs/anchor-sections-1.0.1/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.0.1/anchor-sections.js"></script>


<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>


<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Image-based Profiling Handbook</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a></li>
<li class="chapter" data-level="1" data-path="introduction.html"><a href="introduction.html"><i class="fa fa-check"></i><b>1</b> Introduction</a><ul>
<li class="chapter" data-level="1.1" data-path="introduction.html"><a href="introduction.html#collect-your-software"><i class="fa fa-check"></i><b>1.1</b> Collect your software</a></li>
<li class="chapter" data-level="1.2" data-path="introduction.html"><a href="introduction.html#collect-your-pipelines"><i class="fa fa-check"></i><b>1.2</b> Collect your pipelines</a></li>
<li class="chapter" data-level="1.3" data-path="introduction.html"><a href="introduction.html#determine-how-to-get-your-image-lists-to-cellprofiler"><i class="fa fa-check"></i><b>1.3</b> Determine how to get your image lists to CellProfiler</a></li>
<li class="chapter" data-level="1.4" data-path="introduction.html"><a href="introduction.html#execute-your-cellprofiler-pipelines"><i class="fa fa-check"></i><b>1.4</b> Execute your CellProfiler pipelines</a><ul>
<li class="chapter" data-level="1.4.1" data-path="introduction.html"><a href="introduction.html#optional-z-projection"><i class="fa fa-check"></i><b>1.4.1</b> (Optional) Z projection</a></li>
<li class="chapter" data-level="1.4.2" data-path="introduction.html"><a href="introduction.html#optional-qc"><i class="fa fa-check"></i><b>1.4.2</b> (Optional) QC</a></li>
<li class="chapter" data-level="1.4.3" data-path="introduction.html"><a href="introduction.html#illumination-correction"><i class="fa fa-check"></i><b>1.4.3</b> Illumination correction</a></li>
<li class="chapter" data-level="1.4.4" data-path="introduction.html"><a href="introduction.html#optional-assay-development"><i class="fa fa-check"></i><b>1.4.4</b> (Optional) Assay Development</a></li>
</ul></li>
<li class="chapter" data-level="1.5" data-path="introduction.html"><a href="introduction.html#analysis"><i class="fa fa-check"></i><b>1.5</b> Analysis</a></li>
<li class="chapter" data-level="1.6" data-path="introduction.html"><a href="introduction.html#aggregate-your-data"><i class="fa fa-check"></i><b>1.6</b> Aggregate your data</a></li>
<li class="chapter" data-level="1.7" data-path="introduction.html"><a href="introduction.html#create-and-manipulate-per-well-profiles."><i class="fa fa-check"></i><b>1.7</b> Create and manipulate per-well profiles.</a></li>
</ul></li>
<li class="part"><span><b>I Configuration</b></span></li>
<li class="chapter" data-level="2" data-path="configure-environment-for-full-profiling-pipeline.html"><a href="configure-environment-for-full-profiling-pipeline.html"><i class="fa fa-check"></i><b>2</b> Configure Environment for Full Profiling Pipeline</a><ul>
<li class="chapter" data-level="2.1" data-path="configure-environment-for-full-profiling-pipeline.html"><a href="configure-environment-for-full-profiling-pipeline.html#launch-an-aws-virtual-machine-for-making-csvs-and-running-distributed-cellprofiler"><i class="fa fa-check"></i><b>2.1</b> Launch an AWS Virtual Machine for making CSVs and running Distributed-CellProfiler</a></li>
<li class="chapter" data-level="2.2" data-path="configure-environment-for-full-profiling-pipeline.html"><a href="configure-environment-for-full-profiling-pipeline.html#create-a-tmux-session"><i class="fa fa-check"></i><b>2.2</b> Create a tmux session</a></li>
<li class="chapter" data-level="2.3" data-path="configure-environment-for-full-profiling-pipeline.html"><a href="configure-environment-for-full-profiling-pipeline.html#define-environment-variables"><i class="fa fa-check"></i><b>2.3</b> Define Environment Variables</a></li>
<li class="chapter" data-level="2.4" data-path="configure-environment-for-full-profiling-pipeline.html"><a href="configure-environment-for-full-profiling-pipeline.html#create-directories"><i class="fa fa-check"></i><b>2.4</b> Create Directories</a></li>
<li class="chapter" data-level="2.5" data-path="configure-environment-for-full-profiling-pipeline.html"><a href="configure-environment-for-full-profiling-pipeline.html#download-software"><i class="fa fa-check"></i><b>2.5</b> Download Software</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="setup-images.html"><a href="setup-images.html"><i class="fa fa-check"></i><b>3</b> Setup Images</a><ul>
<li class="chapter" data-level="3.1" data-path="setup-images.html"><a href="setup-images.html#upload-images"><i class="fa fa-check"></i><b>3.1</b> Upload Images</a></li>
<li class="chapter" data-level="3.2" data-path="setup-images.html"><a href="setup-images.html#prepare-images"><i class="fa fa-check"></i><b>3.2</b> Prepare Images</a></li>
<li class="chapter" data-level="3.3" data-path="setup-images.html"><a href="setup-images.html#create-list-of-plates"><i class="fa fa-check"></i><b>3.3</b> Create List of Plates</a></li>
<li class="chapter" data-level="3.4" data-path="setup-images.html"><a href="setup-images.html#create-loaddata-csvs"><i class="fa fa-check"></i><b>3.4</b> Create LoadData CSVs</a></li>
<li class="chapter" data-level="3.5" data-path="setup-images.html"><a href="setup-images.html#upload-image-location-files-to-s3"><i class="fa fa-check"></i><b>3.5</b> Upload image location files to S3</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="run-each-cellprofiler-step.html"><a href="run-each-cellprofiler-step.html"><i class="fa fa-check"></i><b>4</b> Run each CellProfiler step</a><ul>
<li class="chapter" data-level="4.1" data-path="run-each-cellprofiler-step.html"><a href="run-each-cellprofiler-step.html#upload-your-pipelines-to-s3"><i class="fa fa-check"></i><b>4.1</b> Upload your pipelines to S3</a></li>
<li class="chapter" data-level="4.2" data-path="run-each-cellprofiler-step.html"><a href="run-each-cellprofiler-step.html#configure-distributed-cellprofilers-run_batch_general-script"><i class="fa fa-check"></i><b>4.2</b> Configure Distributed-CellProfiler's <code>run_batch_general</code> script</a></li>
<li class="chapter" data-level="4.3" data-path="run-each-cellprofiler-step.html"><a href="run-each-cellprofiler-step.html#configure-distributed-cellprofilers-fleet-file"><i class="fa fa-check"></i><b>4.3</b> Configure Distributed-CellProfiler's fleet file</a></li>
<li class="chapter" data-level="4.4" data-path="run-each-cellprofiler-step.html"><a href="run-each-cellprofiler-step.html#change-required-parameters-in-distributed-cellprofilers-config-file"><i class="fa fa-check"></i><b>4.4</b> Change required parameters in Distributed-CellProfiler's config file</a></li>
<li class="chapter" data-level="4.5" data-path="run-each-cellprofiler-step.html"><a href="run-each-cellprofiler-step.html#run-each-cellprofiler-step-1"><i class="fa fa-check"></i><b>4.5</b> Run each CellProfiler step</a><ul>
<li class="chapter" data-level="4.5.1" data-path="run-each-cellprofiler-step.html"><a href="run-each-cellprofiler-step.html#optional-z-projection-1"><i class="fa fa-check"></i><b>4.5.1</b> (Optional) Z projection</a></li>
<li class="chapter" data-level="4.5.2" data-path="run-each-cellprofiler-step.html"><a href="run-each-cellprofiler-step.html#optional-qc-1"><i class="fa fa-check"></i><b>4.5.2</b> (Optional) QC</a></li>
<li class="chapter" data-level="4.5.3" data-path="run-each-cellprofiler-step.html"><a href="run-each-cellprofiler-step.html#illumination-correction-1"><i class="fa fa-check"></i><b>4.5.3</b> Illumination Correction</a></li>
<li class="chapter" data-level="4.5.4" data-path="run-each-cellprofiler-step.html"><a href="run-each-cellprofiler-step.html#optional-assay-dev"><i class="fa fa-check"></i><b>4.5.4</b> (Optional) Assay Dev</a></li>
<li class="chapter" data-level="4.5.5" data-path="run-each-cellprofiler-step.html"><a href="run-each-cellprofiler-step.html#analysis-1"><i class="fa fa-check"></i><b>4.5.5</b> Analysis</a></li>
</ul></li>
<li class="chapter" data-level="4.6" data-path="run-each-cellprofiler-step.html"><a href="run-each-cellprofiler-step.html#optional-do-any-post-cellprofiler-steps"><i class="fa fa-check"></i><b>4.6</b> (Optional) Do any post-CellProfiler steps</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="create-profiles.html"><a href="create-profiles.html"><i class="fa fa-check"></i><b>5</b> Create Profiles</a><ul>
<li class="chapter" data-level="5.1" data-path="create-profiles.html"><a href="create-profiles.html#confirm-environment-configuration"><i class="fa fa-check"></i><b>5.1</b> Confirm Environment Configuration</a></li>
<li class="chapter" data-level="5.2" data-path="create-profiles.html"><a href="create-profiles.html#add-a-large-ebs-volume-to-your-machine"><i class="fa fa-check"></i><b>5.2</b> Add a large EBS volume to your machine</a></li>
<li class="chapter" data-level="5.3" data-path="create-profiles.html"><a href="create-profiles.html#create-database-backend"><i class="fa fa-check"></i><b>5.3</b> Create Database Backend</a></li>
</ul></li>
<li class="appendix"><span><b>Appendix</b></span></li>
<li class="chapter" data-level="A" data-path="appendix-a.html"><a href="appendix-a.html"><i class="fa fa-check"></i><b>A</b> Appendix A</a><ul>
<li class="chapter" data-level="A.1" data-path="appendix-a.html"><a href="appendix-a.html#project-folder-structure-guidance"><i class="fa fa-check"></i><b>A.1</b> Project folder structure guidance</a></li>
<li class="chapter" data-level="A.2" data-path="appendix-a.html"><a href="appendix-a.html#directory-structure"><i class="fa fa-check"></i><b>A.2</b> Directory structure</a></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Image-based Profiling Handbook</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="create-profiles" class="section level1">
<h1><span class="header-section-number">Chapter 5</span> Create Profiles</h1>
<div id="confirm-environment-configuration" class="section level2">
<h2><span class="header-section-number">5.1</span> Confirm Environment Configuration</h2>
<p>You CAN, if you choose, make your backends with the same machine that you have used to make CSVs and run DCP for CellProfiler. However, we typically do not, since backend creation can take a long time so it is desirable to use 2 machines - a small inexpensive machine with only a few CPUs for all the steps before backends and a larger machine with at least as many CPUs as (the number of plates in your batch +1) for backend creation. Both machines can be turned off when not in use and when off will generate only minimal charges.</p>
<p>To make a new backend machine, follow the identical instructions as the in the section below, only with a larger Instance Type (such as an m4.10xlarge).</p>
<ul>
<li><a href="configure-environment-for-full-profiling-pipeline.html#launch-an-aws-virtual-machine-for-making-csvs-and-running-distributed-cellprofiler">Launch an AWS Virtual Machine for making CSVs and running Distributed-CellProfiler</a></li>
</ul>
<p>Since backend creation also typically requires a large amount of hard disk space, which you pay for whether or not the machine is on, we recommend attaching a large EBS volume to your backend creation machine only when needed, then detaching and terminating it when not in use.</p>
</div>
<div id="add-a-large-ebs-volume-to-your-machine" class="section level2">
<h2><span class="header-section-number">5.2</span> Add a large EBS volume to your machine</h2>
<p>Follow the AWS instructions for <a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ebs-creating-volume.html">creating</a> and <a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ebs-attaching-volume.html">attaching</a> the EBS volume. Two critical factors to note- the volume must be created in the same subnet as your backend creation machine, and should be approximately 2X the size as the analysis files in your batch - this is most easily figured by navigating to that location in the S3 web console and selecting &quot;Actions -&gt; Calculate total size&quot;.</p>
<p>Once the volume is created and attached, ensure the machine is started and SSH connect to it.</p>
<p>Create a temp directory which is required when creating the database backed using <code>cytominer-database</code> (discussed later).</p>
<div class="sourceCode"><pre class="sourceCode sh"><code class="sourceCode bash"><span class="fu">mkdir</span> ~/ebs_tmp</code></pre></div>
<p>Get the name of the disk and attach it.</p>
<div class="sourceCode"><pre class="sourceCode sh"><code class="sourceCode bash"><span class="co"># check the name of the disk</span>
<span class="ex">lsblk</span>

<span class="co">#&gt; NAME    MAJ:MIN RM   SIZE RO TYPE MOUNTPOINT</span>
<span class="co">#&gt; xvda    202:0    0     8G  0 disk</span>
<span class="co">#&gt; └─xvda1 202:1    0     8G  0 part /</span>
<span class="co">#&gt; xvdba    202:80   0   100G  0 disk</span>

<span class="co"># check if it has a file system</span>
<span class="fu">sudo</span> file -s /dev/xvdba
<span class="co"># ...likely not, in which case you get:</span>
<span class="co">#&gt; /dev/xvdf: data</span>

<span class="co"># if no file system, then create it</span>
<span class="fu">sudo</span> mkfs -t ext4 /dev/xvdba

<span class="co"># mount it</span>
<span class="fu">sudo</span> mount /dev/xvdba /home/ubuntu/ebs_tmp/

<span class="co"># change perm</span>
<span class="fu">sudo</span> chmod 777 ~/ebs_tmp/</code></pre></div>
<p>If you are starting from here, make sure the following steps have been completed on your ec2 instance and/or session before proceeding</p>
<ul>
<li><a href="configure-environment-for-full-profiling-pipeline.html#configure-environment-for-full-profiling-pipeline">Configure Environment for Full Profiling Pipeline</a></li>
<li><a href="setup-images.html#create-list-of-plates">Create list of plates</a></li>
</ul>
</div>
<div id="create-database-backend" class="section level2">
<h2><span class="header-section-number">5.3</span> Create Database Backend</h2>
<p>Run creation of sqlite backend as well as aggregation of measurements into per-well profiles. This process can be very slow since the files are read from s3fs/EFS. We recommend first downloading the CSVs files locally on an EBS volume attached to the ec2 instance you are running on, and then ingesting.</p>
<p>To do so, first recreate the analysis output folder structure on the EBS volume:</p>
<div class="sourceCode"><pre class="sourceCode sh"><code class="sourceCode bash"><span class="fu">mkdir</span> -p ~/ebs_tmp/<span class="va">${PROJECT_NAME}</span>/workspace/software

<span class="bu">cd</span> ~/ebs_tmp/<span class="va">${PROJECT_NAME}</span>/workspace/software

<span class="kw">if</span><span class="bu"> [</span> <span class="ot">-d</span> pycytominer<span class="bu"> ]</span>; <span class="kw">then</span> <span class="fu">rm</span> -rf pycytominer<span class="kw">;</span> <span class="kw">fi</span>

<span class="fu">git</span> clone https://github.com/cytomining/pycytominer.git

<span class="bu">cd</span> pycytominer

<span class="fu">git</span> checkout jump

<span class="ex">python3</span> -m pip install -e .</code></pre></div>
<p>The command below first calls <code>cytominer-database ingest</code> to create the SQLite backend, and then pycytominer's <code>aggregate_profiles</code> to create per-well profiles. Once complete, all files are uploaded to S3 and the local cache are deleted.</p>
<p><a href="https://github.com/cytomining/pycytominer/blob/jump/pycytominer/cyto_utils/collate.py">collate.py</a> ingests and indexes the database.</p>
<div class="sourceCode"><pre class="sourceCode sh"><code class="sourceCode bash"><span class="ex">pyenv</span> shell 3.8.10

<span class="fu">mkdir</span> -p  ../../log/<span class="va">${BATCH_ID}</span>/
<span class="ex">parallel</span> \
--max-procs <span class="va">${MAXPROCS}</span> \
--ungroup \
--eta \
--joblog ../../log/<span class="va">${BATCH_ID}</span>/collate.log \
--results ../../log/<span class="va">${BATCH_ID}</span>/collate \
--files \
--keep-order \
python3 pycytominer/cyto_utils/collate.py <span class="va">${BATCH_ID}</span>  pycytominer/cyto_utils/ingest_config.ini <span class="dt">{1}</span> \
--temp ~/ebs_tmp \
--remote=s3://<span class="va">${BUCKET}</span>/projects/<span class="va">${PROJECT_NAME}</span>/workspace :::: <span class="va">${PLATES}</span></code></pre></div>

<div class="rmdnote">
<code>collate.py</code> does not recreate the SQLite backend if it already exists in the local cache. Add <code>--overwrite</code> flag to recreate.
</div>


<div class="rmdnote">
For pipelines that use FlagImage to skip the measurements modules if the image failed QC, the failed images will have Image.csv files with fewer columns that the rest (because columns corresponding to aggregated measurements will be absent). The ingest command will show a warning related to sqlite: <code>expected X columns but found Y - filling the rest with NULL</code>. This is expected behavior.
</div>


<div class="rmdnote">
There is a known <a href="https://github.com/cytomining/cytominer-database/issues/100">issue</a> where if the alphabetically-first CSV failed QC in a pipeline where &quot;Skip image if flagged&quot; is turned on, the databases will not be created. We are working to fix this, but in the meantime we recommend either not skipping processing of your flagged images (and removing them from your data downstream) or deleting the alphabetically-first CSVs until you come to one where the pipeline ran completely.
</div>

<p>This is the resulting structure of <code>backend</code> on S3 (one level below <code>workspace</code>) for <code>SQ00015167</code>:</p>
<pre><code>└── backend
    └── 2016_04_01_a549_48hr_batch1
        └── SQ00015167
            ├── SQ00015167.csv
            └── SQ00015167.sqlite</code></pre>
<p>At this point, the user needs to use the <a href="https://github.com/cytomining/profiling-template">profiling template</a> to use <a href="https://github.com/cytomining/pycytominer/">pycytominer</a> to annotate the profiles with metadata, normalize them, and feature select them. Detailed instructions for these steps will be added as soon as possible.</p>

</div>
</div>



            </section>

          </div>
        </div>
      </div>
<a href="run-each-cellprofiler-step.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="appendix-a.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/cytomining/profiling-handbook/edit/master/05-create-profiles.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["bookdown-demo.pdf", "bookdown-demo.epub"],
"search": {
"engine": "lunr",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

</body>

</html>
