<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 3 Setup Images | Image-based Profiling Handbook</title>
  <meta name="description" content="This is a handbook for processing image-based profiling datasets using CellProfiler and pycytominer" />
  <meta name="generator" content="bookdown 0.22.5 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 3 Setup Images | Image-based Profiling Handbook" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="This is a handbook for processing image-based profiling datasets using CellProfiler and pycytominer" />
  <meta name="github-repo" content="rstudio/bookdown-demo" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 3 Setup Images | Image-based Profiling Handbook" />
  
  <meta name="twitter:description" content="This is a handbook for processing image-based profiling datasets using CellProfiler and pycytominer" />
  

<meta name="author" content="Beth Cimini, Tim Becker, Shantanu Singh, Gregory Way, Hamdah Abbasi" />


<meta name="date" content="2021-06-25" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="configure-environment-for-full-profiling-pipeline.html"/>
<link rel="next" href="run-each-cellprofiler-step.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<link href="libs/anchor-sections-1.0.1/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.0.1/anchor-sections.js"></script>


<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>


<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Image-based Profiling Handbook</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a></li>
<li class="chapter" data-level="1" data-path="introduction.html"><a href="introduction.html"><i class="fa fa-check"></i><b>1</b> Introduction</a><ul>
<li class="chapter" data-level="1.1" data-path="introduction.html"><a href="introduction.html#collect-your-software"><i class="fa fa-check"></i><b>1.1</b> Collect your software</a></li>
<li class="chapter" data-level="1.2" data-path="introduction.html"><a href="introduction.html#collect-your-pipelines"><i class="fa fa-check"></i><b>1.2</b> Collect your pipelines</a></li>
<li class="chapter" data-level="1.3" data-path="introduction.html"><a href="introduction.html#determine-how-to-get-your-image-lists-to-cellprofiler"><i class="fa fa-check"></i><b>1.3</b> Determine how to get your image lists to CellProfiler</a></li>
<li class="chapter" data-level="1.4" data-path="introduction.html"><a href="introduction.html#execute-your-cellprofiler-pipelines"><i class="fa fa-check"></i><b>1.4</b> Execute your CellProfiler pipelines</a><ul>
<li class="chapter" data-level="1.4.1" data-path="introduction.html"><a href="introduction.html#optional-z-projection"><i class="fa fa-check"></i><b>1.4.1</b> (Optional) Z projection</a></li>
<li class="chapter" data-level="1.4.2" data-path="introduction.html"><a href="introduction.html#optional-qc"><i class="fa fa-check"></i><b>1.4.2</b> (Optional) QC</a></li>
<li class="chapter" data-level="1.4.3" data-path="introduction.html"><a href="introduction.html#illumination-correction"><i class="fa fa-check"></i><b>1.4.3</b> Illumination correction</a></li>
<li class="chapter" data-level="1.4.4" data-path="introduction.html"><a href="introduction.html#optional-assay-development"><i class="fa fa-check"></i><b>1.4.4</b> (Optional) Assay Development</a></li>
</ul></li>
<li class="chapter" data-level="1.5" data-path="introduction.html"><a href="introduction.html#analysis"><i class="fa fa-check"></i><b>1.5</b> Analysis</a></li>
<li class="chapter" data-level="1.6" data-path="introduction.html"><a href="introduction.html#aggregate-your-data"><i class="fa fa-check"></i><b>1.6</b> Aggregate your data</a></li>
<li class="chapter" data-level="1.7" data-path="introduction.html"><a href="introduction.html#create-and-manipulate-per-well-profiles."><i class="fa fa-check"></i><b>1.7</b> Create and manipulate per-well profiles.</a></li>
</ul></li>
<li class="part"><span><b>I Configuration</b></span></li>
<li class="chapter" data-level="2" data-path="configure-environment-for-full-profiling-pipeline.html"><a href="configure-environment-for-full-profiling-pipeline.html"><i class="fa fa-check"></i><b>2</b> Configure Environment for Full Profiling Pipeline</a><ul>
<li class="chapter" data-level="2.1" data-path="configure-environment-for-full-profiling-pipeline.html"><a href="configure-environment-for-full-profiling-pipeline.html#launch-an-aws-virtual-machine-for-making-csvs-and-running-distributed-cellprofiler"><i class="fa fa-check"></i><b>2.1</b> Launch an AWS Virtual Machine for making CSVs and running Distributed-CellProfiler</a></li>
<li class="chapter" data-level="2.2" data-path="configure-environment-for-full-profiling-pipeline.html"><a href="configure-environment-for-full-profiling-pipeline.html#create-a-tmux-session"><i class="fa fa-check"></i><b>2.2</b> Create a tmux session</a></li>
<li class="chapter" data-level="2.3" data-path="configure-environment-for-full-profiling-pipeline.html"><a href="configure-environment-for-full-profiling-pipeline.html#define-environment-variables"><i class="fa fa-check"></i><b>2.3</b> Define Environment Variables</a></li>
<li class="chapter" data-level="2.4" data-path="configure-environment-for-full-profiling-pipeline.html"><a href="configure-environment-for-full-profiling-pipeline.html#create-directories"><i class="fa fa-check"></i><b>2.4</b> Create Directories</a></li>
<li class="chapter" data-level="2.5" data-path="configure-environment-for-full-profiling-pipeline.html"><a href="configure-environment-for-full-profiling-pipeline.html#download-software"><i class="fa fa-check"></i><b>2.5</b> Download Software</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="setup-images.html"><a href="setup-images.html"><i class="fa fa-check"></i><b>3</b> Setup Images</a><ul>
<li class="chapter" data-level="3.1" data-path="setup-images.html"><a href="setup-images.html#upload-images"><i class="fa fa-check"></i><b>3.1</b> Upload Images</a></li>
<li class="chapter" data-level="3.2" data-path="setup-images.html"><a href="setup-images.html#prepare-images"><i class="fa fa-check"></i><b>3.2</b> Prepare Images</a></li>
<li class="chapter" data-level="3.3" data-path="setup-images.html"><a href="setup-images.html#create-list-of-plates"><i class="fa fa-check"></i><b>3.3</b> Create List of Plates</a></li>
<li class="chapter" data-level="3.4" data-path="setup-images.html"><a href="setup-images.html#create-loaddata-csvs"><i class="fa fa-check"></i><b>3.4</b> Create LoadData CSVs</a></li>
<li class="chapter" data-level="3.5" data-path="setup-images.html"><a href="setup-images.html#upload-image-location-files-to-s3"><i class="fa fa-check"></i><b>3.5</b> Upload image location files to S3</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="run-each-cellprofiler-step.html"><a href="run-each-cellprofiler-step.html"><i class="fa fa-check"></i><b>4</b> Run each CellProfiler step</a><ul>
<li class="chapter" data-level="4.1" data-path="run-each-cellprofiler-step.html"><a href="run-each-cellprofiler-step.html#upload-your-pipelines-to-s3"><i class="fa fa-check"></i><b>4.1</b> Upload your pipelines to S3</a></li>
<li class="chapter" data-level="4.2" data-path="run-each-cellprofiler-step.html"><a href="run-each-cellprofiler-step.html#configure-distributed-cellprofilers-run_batch_general-script"><i class="fa fa-check"></i><b>4.2</b> Configure Distributed-CellProfiler's <code>run_batch_general</code> script</a></li>
<li class="chapter" data-level="4.3" data-path="run-each-cellprofiler-step.html"><a href="run-each-cellprofiler-step.html#configure-distributed-cellprofilers-fleet-file"><i class="fa fa-check"></i><b>4.3</b> Configure Distributed-CellProfiler's fleet file</a></li>
<li class="chapter" data-level="4.4" data-path="run-each-cellprofiler-step.html"><a href="run-each-cellprofiler-step.html#change-required-parameters-in-distributed-cellprofilers-config-file"><i class="fa fa-check"></i><b>4.4</b> Change required parameters in Distributed-CellProfiler's config file</a></li>
<li class="chapter" data-level="4.5" data-path="run-each-cellprofiler-step.html"><a href="run-each-cellprofiler-step.html#run-each-cellprofiler-step-1"><i class="fa fa-check"></i><b>4.5</b> Run each CellProfiler step</a><ul>
<li class="chapter" data-level="4.5.1" data-path="run-each-cellprofiler-step.html"><a href="run-each-cellprofiler-step.html#optional-z-projection-1"><i class="fa fa-check"></i><b>4.5.1</b> (Optional) Z projection</a></li>
<li class="chapter" data-level="4.5.2" data-path="run-each-cellprofiler-step.html"><a href="run-each-cellprofiler-step.html#optional-qc-1"><i class="fa fa-check"></i><b>4.5.2</b> (Optional) QC</a></li>
<li class="chapter" data-level="4.5.3" data-path="run-each-cellprofiler-step.html"><a href="run-each-cellprofiler-step.html#illumination-correction-1"><i class="fa fa-check"></i><b>4.5.3</b> Illumination Correction</a></li>
<li class="chapter" data-level="4.5.4" data-path="run-each-cellprofiler-step.html"><a href="run-each-cellprofiler-step.html#optional-assay-dev"><i class="fa fa-check"></i><b>4.5.4</b> (Optional) Assay Dev</a></li>
<li class="chapter" data-level="4.5.5" data-path="run-each-cellprofiler-step.html"><a href="run-each-cellprofiler-step.html#analysis-1"><i class="fa fa-check"></i><b>4.5.5</b> Analysis</a></li>
</ul></li>
<li class="chapter" data-level="4.6" data-path="run-each-cellprofiler-step.html"><a href="run-each-cellprofiler-step.html#optional-do-any-post-cellprofiler-steps"><i class="fa fa-check"></i><b>4.6</b> (Optional) Do any post-CellProfiler steps</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="create-profiles.html"><a href="create-profiles.html"><i class="fa fa-check"></i><b>5</b> Create Profiles</a><ul>
<li class="chapter" data-level="5.1" data-path="create-profiles.html"><a href="create-profiles.html#confirm-environment-configuration"><i class="fa fa-check"></i><b>5.1</b> Confirm Environment Configuration</a></li>
<li class="chapter" data-level="5.2" data-path="create-profiles.html"><a href="create-profiles.html#add-a-large-ebs-volume-to-your-machine"><i class="fa fa-check"></i><b>5.2</b> Add a large EBS volume to your machine</a></li>
<li class="chapter" data-level="5.3" data-path="create-profiles.html"><a href="create-profiles.html#create-database-backend"><i class="fa fa-check"></i><b>5.3</b> Create Database Backend</a></li>
</ul></li>
<li class="appendix"><span><b>Appendix</b></span></li>
<li class="chapter" data-level="A" data-path="appendix-a.html"><a href="appendix-a.html"><i class="fa fa-check"></i><b>A</b> Appendix A</a><ul>
<li class="chapter" data-level="A.1" data-path="appendix-a.html"><a href="appendix-a.html#project-folder-structure-guidance"><i class="fa fa-check"></i><b>A.1</b> Project folder structure guidance</a></li>
<li class="chapter" data-level="A.2" data-path="appendix-a.html"><a href="appendix-a.html#directory-structure"><i class="fa fa-check"></i><b>A.2</b> Directory structure</a></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Image-based Profiling Handbook</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="setup-images" class="section level1">
<h1><span class="header-section-number">Chapter 3</span> Setup Images</h1>
<div id="upload-images" class="section level2">
<h2><span class="header-section-number">3.1</span> Upload Images</h2>
<p>Your image files should be uploaded to AWS from your local compute environment via a tool like <a href="https://cyberduck.io/">Cyberduck</a> or the <a href="https://aws.amazon.com/cli/">AWS CLI</a> (<code>aws s3 sync /local/path s3://BUCKET/PROJECT_NAME/BATCH_ID/images</code>) (see also Appendix A.2 for more information on folder structures). Some important tips BEFORE uploading (these are much more difficult to fix once uploaded):</p>
<ul>
<li>Ensure your image sets are complete i.e. all image sets should have the same number of channels and z-planes, and that this is true across the entire batch of plates you are processing.</li>
<li>Avoid folder names with spaces</li>
<li>Plate names should not have leading 0's (ie <code>123</code> not <code>000123</code>)</li>
<li><em>VERY IMPORTANT</em>: If using <code>pe2loaddata</code> (described later) to generate your image CSVs, please ensure the folder name contains the plate name given when imaging on the Phenix microscope (can be checked in the <code>Index.idx.xml</code>)</li>
</ul>
</div>
<div id="prepare-images" class="section level2">
<h2><span class="header-section-number">3.2</span> Prepare Images</h2>
<p>(if using <code>pe2loaddata</code> to create image sets)</p>
<p>Create soft link to the image folder. Note that the relevant S3 bucket has been mounted at <code>/home/ubuntu/bucket/</code>.</p>

<div class="rmdnote">
<p>The folder structure for <code>images</code> differs between <code>S3</code> and <code>EFS</code>. This can be potentially confusing. However note that the step below simply creates a soft link to the images in S3; no files are copied. Further, when <code>pe2loaddata</code> is run, the <code>--sub-string-out</code> and <code>--sub-string-in</code> flags ensure the resulting LoadData CSV files end up having the paths to the images as they exist on S3. Thus the step below (of creating a softlink) only serves the purpose of making the <code>images</code> folder have a similar structure as the others (e.g. <code>load_data_csv</code>, <code>metadata</code>, <code>analysis</code>).</p>
If you’re Z-projecting images and the unprojected images are in a folder with a different name (such as /unprojected_images/), you should create the soft link to that folder: <code>ln -s ~/bucket/projects/${PROJECT_NAME}/${BATCH_ID}/unprojected_images/ ${BATCH_ID}</code>
</div>

<div class="sourceCode"><pre class="sourceCode sh"><code class="sourceCode bash"><span class="bu">cd</span> ~/efs/<span class="va">${PROJECT_NAME}</span>/workspace/
<span class="fu">mkdir</span> images <span class="co">#Run this only if this is the first batch for this project</span>
<span class="bu">cd</span> images
<span class="fu">ln</span> -s ~/bucket/projects/<span class="va">${PROJECT_NAME}</span>/<span class="va">${BATCH_ID}</span>/images/ <span class="va">${BATCH_ID}</span>
<span class="bu">cd</span> ..</code></pre></div>
<p>This is the resulting structure of the image folder on EFS (one level below <code>workspace</code>):</p>
<pre><code>└── images
    └── 2016_04_01_a549_48hr_batch1 -&gt; /home/ubuntu/bucket/projects/2015_10_05_DrugRepurposing_AravindSubramanian_GolubLab_Broad/2016_04_01_a549_48hr_batch1/images/</code></pre>
<p>This is the structure of the image folder on S3 (one level above <code>workspace</code>, under the folder <code>2016_04_01_a549_48hr_batch1</code>.) Here, only one plate (<code>SQ00015167__2016-04-21T03_34_00-Measurement1</code>) is show but there are often many more.</p>
<pre><code>└── images
    └── 2016_04_01_a549_48hr_batch1
        └── SQ00015167__2016-04-21T03_34_00-Measurement1
            ├── Assaylayout
            ├── FFC_Profile
            └── Images
                ├── r01c01f01p01-ch1sk1fk1fl1.tiff
                ├── r01c01f01p01-ch2sk1fk1fl1.tiff
                ├── r01c01f01p01-ch3sk1fk1fl1.tiff
                ├── r01c01f01p01-ch4sk1fk1fl1.tiff
                └── r01c01f01p01-ch5sk1fk1fl1.tiff</code></pre>
<p><code>SQ00015167__2016-04-21T03_34_00-Measurement1</code> is the typical nomenclature followed by Broad Chemical Biology Platform for plate names. <code>Measurement1</code> indicates the first attempt to image the plate. <code>Measurement2</code> indicates second attempt and so on.</p>
</div>
<div id="create-list-of-plates" class="section level2">
<h2><span class="header-section-number">3.3</span> Create List of Plates</h2>
<p>(if using <code>pe2loaddata</code> to create image sets)</p>
<p>Create a text file with one plate id per line. The plate IDs, if using <code>pe2loaddata</code>, must match the plate IDs given when operating the Phenix. Otherwise, they should match CellProfiler's understanding of the <code>Plate</code> grouping variable, whether that is explicitly stated in a loaddata CSV OR produced from the Metadata module if the CSVs and/or batch files are created using CellProfiler's input modules. For downstream purposes, i.e. <code>cytominer</code>, you may choose to use only so much of the plate name as you need to keep the plates unique (e.g. <code>SQ00015167</code> instead of <code>SQ00015167__2016-04-21T03_34_00-Measurement1</code> to keep the names compact.</p>
<div class="sourceCode"><pre class="sourceCode sh"><code class="sourceCode bash">
<span class="fu">mkdir</span> -p ~/efs/<span class="va">${PROJECT_NAME}</span>/workspace/scratch/<span class="va">${BATCH_ID}</span>/

<span class="va">PLATES=$(</span><span class="fu">readlink</span> -f ~/efs/<span class="va">${PROJECT_NAME}</span>/workspace/scratch/<span class="va">${BATCH_ID}</span>/plates_to_process.txt<span class="va">)</span>

<span class="va">FULL_PLATES=$(</span><span class="fu">readlink</span> -f ~/efs/<span class="va">${PROJECT_NAME}</span>/workspace/scratch/<span class="va">${BATCH_ID}</span>/full_plates_to_process.txt<span class="va">)</span>

<span class="fu">ls</span> ~/efs/<span class="va">${PROJECT_NAME}</span>/workspace/images/<span class="va">${BATCH_ID}</span>/ <span class="kw">|</span> <span class="fu">cut</span> -d <span class="st">&#39;_&#39;</span> -f 1 <span class="op">&gt;&gt;</span> <span class="va">$PLATES</span>

<span class="fu">ls</span> ~/efs/<span class="va">${PROJECT_NAME}</span>/workspace/images/<span class="va">${BATCH_ID}</span>/ <span class="op">&gt;&gt;</span> <span class="va">$FULL_PLATES</span></code></pre></div>
<p>Check that your plate names are correct by <code>nano $PLATES</code> and <code>nano $FULL_PLATES</code>. If your plate names contain underscores, you may need to fix the simplified plate names. Both should have the same number of rows as the number of plates in your batch.</p>
<p><code>SAMPLE_PLATE_ID=PLATE_NAME_1</code> This can be any single plate name, again using the portion of the name that is before the double underscore <code>__</code>.</p>
<p><code>SAMPLE_FULL_PLATE_NAME=FULL_PLATE_NAME_1</code> This can be any single plate name, this time using the full name.</p>
</div>
<div id="create-loaddata-csvs" class="section level2">
<h2><span class="header-section-number">3.4</span> Create LoadData CSVs</h2>
<p>(if using <code>pe2loaddata</code> to create image sets)</p>
<p>The script below works only for Phenix microscopes – it reads a standard XML file (<code>Index.idx.xml</code>) and writes a LoadData CSV file. For other microscopes, you will have to roll your own (see the overview chapter for more information). The script below requires <code>config.yml</code>, which specifies</p>
<ol style="list-style-type: decimal">
<li>the mapping between channel names in <code>Index.idx.xml</code> and the channel names in the CellProfiler pipelines</li>
<li>metadata to extract from <code>Index.idx.xml</code></li>
</ol>
<p>Here's a truncated sample <code>config.yml</code> (here is an example of the <a href="https://github.com/broadinstitute/pe2loaddata/blob/220ac512bfc0c2e582d379b19411c1585272aee3/config.yml">full file</a>)</p>
<pre><code>channels:
    HOECHST 33342: OrigDNA
    Alexa 568: OrigAGP
    Alexa 647: OrigMito
    Alexa 488: OrigER
    488 long: OrigRNA
    Brightfieldlow: OrigBrightfield
metadata:
    Row: Row
    Col: Col
    FieldID: FieldID
    PlaneID: PlaneID
    ChannelID: ChannelID
    ChannelName: ChannelName
    ImageResolutionX: ImageResolutionX
    [...]</code></pre>
<p>Often, the values of the keys for channels are different in <code>Index.idx.xml</code>, so for example, above, we have <code>Brightfieldlow: OrigBrightfield</code> but the keys for channels could be different in <code>Index.idx.xml</code>:</p>
<pre><code>$ tail -n 500 ~/efs/${PROJECT_NAME}/workspace/images/${BATCH_ID}/${SAMPLE_FULL_PLATE_NAME}/Images/Index.idx.xml|grep ChannelName|sort -u

      &lt;ChannelName&gt;488 long&lt;/ChannelName&gt;
      &lt;ChannelName&gt;Alexa 488&lt;/ChannelName&gt;
      &lt;ChannelName&gt;Alexa 568&lt;/ChannelName&gt;
      &lt;ChannelName&gt;Alexa 647&lt;/ChannelName&gt;
      &lt;ChannelName&gt;Brightfield CP&lt;/ChannelName&gt;
      &lt;ChannelName&gt;HOECHST 33342&lt;/ChannelName&gt;</code></pre>
<p>Copy the text into a text file somewhere on your computer so you can refer to it.</p>
<p>Now navigate to your pe2loaddata repository and ensure that it is up to date</p>
<div class="sourceCode"><pre class="sourceCode sh"><code class="sourceCode bash"><span class="bu">cd</span> ~/efs/<span class="va">${PROJECT_NAME}</span>/workspace/software/pe2loaddata

<span class="fu">git</span> pull

<span class="ex">pyenv</span> shell 3.8.10

<span class="ex">pip3</span> install -e . </code></pre></div>
<p>Adjust any discrepancies between the list of channels from your index file and the config by editing <code>config.yml</code>:</p>
<pre><code>    HOECHST 33342: OrigDNA
    Alexa 568: OrigAGP
    Alexa 647: OrigMito
    Alexa 488: OrigER
    488 long: OrigRNA
    Brightfield CP: OrigBrightfield</code></pre>

<div class="rmdnote">
<ul>
<li>Ensure that all the metadata fields defined in <code>config.yml</code> are present in the <code>Index.idx.xml</code>.</li>
<li>Ensure that the channel names are the same in <code>config.yml</code> and <code>Index.idx.xml</code></li>
<li>Ensure that the LoadData csv files don't already exist; if they do, delete them.</li>
<li>The <code>max-procs</code> option is set as 1 because pe2loaddata accesses the image files on <code>s3fs</code>, which doesn't handle multiple requests well.</li>
<li>If your images require Z projection, make sure that <code>sub-string-in</code> is set to the folder that you soft-linked to in the previous step.
</div>
</li>
</ul>
<div class="sourceCode"><pre class="sourceCode sh"><code class="sourceCode bash"><span class="ex">pyenv</span> shell 3.8.10
<span class="ex">parallel</span> \
  --link \
  --max-procs 1 \
  --eta \
  --joblog ../../log/<span class="va">${BATCH_ID}</span>/create_csv_from_xml.log \
  --results ../../log/<span class="va">${BATCH_ID}</span>/create_csv_from_xml \
  --files \
  --keep-order \
  pe2loaddata config.yml \
    ~/efs/<span class="va">${PROJECT_NAME}</span>/workspace/load_data_csv/<span class="va">${BATCH_ID}</span>/<span class="dt">{1}</span>/load_data.csv \
    --index-directory ~/efs/<span class="va">${PROJECT_NAME}</span>/workspace/images/<span class="va">${BATCH_ID}</span>/<span class="dt">{2}</span>/Images \
    --illum \
    --illum-directory /home/ubuntu/bucket/projects/<span class="va">${PROJECT_NAME}</span>/<span class="va">${BATCH_ID}</span>/illum/<span class="dt">{1}</span> \
    --plate-id <span class="dt">{1}</span> \
    --illum-output ~/efs/<span class="va">${PROJECT_NAME}</span>/workspace/load_data_csv/<span class="va">${BATCH_ID}</span>/<span class="dt">{1}</span>/load_data_with_illum.csv \
    --sub-string-out efs/<span class="va">${PROJECT_NAME}</span>/workspace/images/<span class="va">${BATCH_ID}</span> \
    --sub-string-in bucket/projects/<span class="va">${PROJECT_NAME}</span>/<span class="va">${BATCH_ID}</span>/images :::: <span class="va">${PLATES}</span> <span class="va">${FULL_PLATES}</span></code></pre></div>
<p>This is the resulting structure of <code>load_data_csv</code> on EFS (one level below <code>workspace</code>). Files for only <code>SQ00015167</code> are shown.</p>
<pre><code>└── load_data_csv
    └── 2016_04_01_a549_48hr_batch1
        └── SQ00015167
            ├── load_data.csv
            └── load_data_with_illum.csv</code></pre>
<p><code>load_data.csv</code> will be used by <code>illum.cppipe</code> and, optionally, <code>qc.cppipe</code>. <code>load_data_with_illum.csv</code> will be used by <code>analysis.cppipe</code> and, optionally, <code>assaydev.cppipe</code>. When creating <code>load_data_with_illum.csv</code>, the script assumes a specific location for the folder containing the illumination correction files.</p>

<div class="rmdnote">
<p>If your files must be Z projected, your load_data.csv will be correct for that step. Once that step is executed, edit BOTH of your CSVs to ensure that</p>
<ul>
<li>The <code>Orig</code> image paths are updated to the location of the projected files rather than than the unprojected files</li>
<li>Only the last-numbered plane from each site are kept</li>
</ul>
These steps can be done manually in e.g. in Excel but are easier to script for large numbers of plates.<br />
You should then upload your edited CSVs to S3.
</div>

</div>
<div id="upload-image-location-files-to-s3" class="section level2">
<h2><span class="header-section-number">3.5</span> Upload image location files to S3</h2>
<p>If using <code>pe2loaddata</code>, run the command below</p>
<p>Copy the load data files to S3:</p>
<div class="sourceCode"><pre class="sourceCode sh"><code class="sourceCode bash"><span class="ex">aws</span> s3 sync \
  ~/efs/<span class="va">${PROJECT_NAME}</span>/workspace/load_data_csv/<span class="va">${BATCH_ID}</span>/ \
  s3://<span class="va">${BUCKET}</span>/projects/<span class="va">${PROJECT_NAME}</span>/workspace/load_data_csv/<span class="va">${BATCH_ID}</span>/</code></pre></div>
<p>If using your own home-created load data CSVs, load them to the same location - <code>s3://${BUCKET}/projects/${PROJECT_NAME}/workspace/load_data_csv/${BATCH_ID}</code> - we strongly recommend the structure of making one subfolder with CSVs in it per plate and then using the names <code>load_data.csv</code> for CSVs without illum files and <code>load_data_with_illum.csv</code> for those with the illum files.</p>
<p>If using batch files, we recommend uploading them to <code>s3://${BUCKET}/projects/${PROJECT_NAME}/workspace/batchfiles/${BATCH_ID}</code>, giving each batch file a unique name to reflect which step it is for - since the process of creating batchfiles can be onerous, subsequent steps assume you will make one batchfile per batch rather than per plate, but you may adjust this if you like.</p>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="configure-environment-for-full-profiling-pipeline.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="run-each-cellprofiler-step.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/cytomining/profiling-handbook/edit/master/03-setup-images.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["bookdown-demo.pdf", "bookdown-demo.epub"],
"search": {
"engine": "lunr",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

</body>

</html>
